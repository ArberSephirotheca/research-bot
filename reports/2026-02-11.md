# GPU Research Digest — 2026-02-11
Generated: 2026-02-11T14:28:53.534798864+00:00
Sources: 12
New items: 3
Already seen: 17
Window: last 90 days
Sources failed: 5

## arXiv: GPU OR CUDA
- No new items found in the last 90 days.

## arXiv: ML + GPU
- No new items found in the last 90 days.

## arXiv: Matrix Multiplication + GPU
- No new items found in the last 90 days.

## arXiv: AI/ML + GPU
- No new items found in the last 90 days.

## Search: last 90 days Hopper H100 tensor cores FP8 GEMM microarchitecture paper
- No new items found in the last 90 days.

## Search: last 90 days Blackwell B200 tensor cores FP4 FP8 GEMM performance analysis (error)
- Fetch error: web_search returned no in-window results (cutoff 2025-11-13)

## Search: last 90 days CUTLASS 3.x new GEMM kernels SM90 SM100 tutorial blog (new: 1, showing: 1)
- [SM121 CUTLASS Kernel Optimization Results: NVFP4 356 TFLOPS, MoE Grouped GEMM on DGX Spark](https://forums.developer.nvidia.com/t/sm121-cutlass-kernel-optimization-results-nvfp4-356-tflops-moe-grouped-gemm-on-dgx-spark/359960) — 2026-02-07
  - Authors: n/a
  - Affiliations: not provided
  - Reports SM121 (GB10 / DGX Spark) CUTLASS 4.4.0 + CUDA 13.1 kernel-tuning results, highlighting NVFP4 GEMM performance reaching ~356 TFLOPS, indicating strong low-precision tensor-core throughput on this architecture.
  - Includes Mixture-of-Experts (MoE) grouped GEMM benchmarks/optimizations at the CUTLASS kernel level, relevant for improving expert-parallel matmul efficiency and reducing launch/dispatch overhead.
  - Provides reproducible environment/config details (toolkit + CUTLASS versions, hardware context) useful for practitioners comparing GEMM kernel performance across SM generations and precision modes.

## Search: last 90 days cuBLASLt GEMM autotuning heuristics SM90 SM100 release notes (error)
- Fetch error: web_search returned no in-window results (cutoff 2025-11-13)

## Search: last 90 days Triton compiler matmul kernel fusion persistent kernels research (new: 2, showing: 2)
- [FlashSinkhorn: IO-Aware Entropic Optimal Transport](https://arxiv.org/abs/2602.03067) — 2026-02-03
  - Authors: n/a
  - Affiliations: not provided
  - Uses FlashAttention-style tiling/fusion for Sinkhorn iterations so the core ops (row/col log-sum-exp + scaling) stay on-chip longer, cutting HBM traffic per iteration and improving throughput on modern GPUs.
  - Implements fused Triton kernels that combine multiple Sinkhorn update steps (normalization, exponentiation/log-domain stabilization, reductions) to reduce kernel launches and intermediate reads/writes—IO-aware rather than FLOP-bound.
  - Recasts entropic OT/Sinkhorn as a sequence of structured matrix-vector/matrix operations (e.g., applying the Gibbs kernel / cost-based exponentials) and optimizes the “matmul-adjacent” reductions and scaling around them to better utilize GPU memory hierarchy.
- [Fused Triton Kernels in LLM Optimization](https://www.emergentmind.com/topics/fused-triton-kernels) — 2026-01-07
  - Authors: n/a
  - Affiliations: not provided
  - Uses Triton to fuse common LLM subgraphs (e.g., linear/GEMM-adjacent ops + bias/activation/dropout/normalization) into single GPU kernel launches, reducing launch overhead and improving data locality around matrix-multiplication-heavy blocks.
  - Reports speedups and lower memory traffic by keeping intermediates in registers/shared memory instead of writing to global memory between ops—especially beneficial when GEMM outputs feed immediately into elementwise/normalization steps.
  - Highlights practical tradeoffs for practitioners: fusion can be bandwidth/latency wins but may reduce flexibility (shape/dtype constraints) and requires careful tuning of tiling, warps, and memory layouts to avoid hurting GEMM throughput.

## Search: last 90 days FlashAttention-3 CUDA kernel tensor core GEMM tiling paper (error)
- Fetch error: web_search returned no in-window results (cutoff 2025-11-13)

## Search: last 90 days GPU systolic array mapping GEMM tensor core scheduling research (error)
- Fetch error: web_search returned no in-window results (cutoff 2025-11-13)

## Search: last 90 days MLIR LLVM NVPTX GPU compiler matmul codegen tensor cores research (error)
- Fetch error: web_search returned no in-window results (cutoff 2025-11-13)
