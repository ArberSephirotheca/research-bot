# GPU Research Digest — 2026-01-02
Generated: 2026-01-02T14:08:25.506052581+00:00
Sources: 12
New items: 3
Already seen: 18
Window: last 90 days
Sources failed: 5

## arXiv: GPU OR CUDA
- No new items found in the last 90 days.

## arXiv: ML + GPU
- No new items found in the last 90 days.

## arXiv: Matrix Multiplication + GPU
- No new items found in the last 90 days.

## arXiv: AI/ML + GPU
- No new items found in the last 90 days.

## Search: last 90 days NVIDIA Hopper H100 tensor cores GEMM research paper (new: 1, showing: 1)
- [Microbenchmarking NVIDIA's Blackwell Architecture: An in-depth Architectural Analysis](https://www.emergentmind.com/papers/2512.02189) — 2025-12-01
  - Authors: n/a
  - Affiliations: not provided
  - Open-source microbenchmark suite characterizes NVIDIA Blackwell SM behavior and contrasts it with H200/Hopper, highlighting changes that matter for GEMM-heavy workloads.
  - Probes tensor core pipeline details and precision/mode behavior (e.g., mixed-precision paths), helping practitioners predict throughput/latency tradeoffs for matrix multiplication kernels.
  - Provides actionable low-level measurements (instruction/pipe utilization, scheduling/latency effects) to guide GEMM tuning and performance modeling on Blackwell vs Hopper.

## Search: last 90 days CUDA 12.4 cuBLASLt GEMM performance improvements blog (error)
- Fetch error: web_search returned no in-window results (cutoff 2025-10-04)

## Search: last 90 days CUTLASS 3.x grouped GEMM epilogue fusion kernel research (error)
- Fetch error: web_search returned no in-window results (cutoff 2025-10-04)

## Search: last 90 days Triton compiler matmul autotuning tensor core wgmma research (new: 1, showing: 1)
- [Block Scaled Matrix Multiplication — Triton documentation](https://triton-lang.org/main/getting-started/tutorials/10-block-scaled-matmul.html) — 2025-12-28
  - Authors: n/a
  - Affiliations: not provided
  - Explains Triton’s block-scaled GEMM for low-precision FP4/FP8, targeting 5th-gen NVIDIA Tensor Cores (SM10 / compute capability 10) and AMD CDNA4 matrix cores, with emphasis on how block scaling enables efficient matmul at very low precision.
  - Covers practical kernel construction details in Triton (data layouts, scaling metadata, accumulation/epilogue choices) and the supported block-scaled formats/options relevant to Tensor Core / matrix-core execution.
  - Includes benchmarking guidance/results to compare throughput/latency across formats and hardware, helping practitioners choose FP4 vs FP8 block-scaled matmul configurations for performance.

## Search: last 90 days FlashAttention-3 GPU kernel matmul softmax tensor cores paper (error)
- Fetch error: web_search returned no in-window results (cutoff 2025-10-04)

## Search: last 90 days GPU systolic array matrix multiplication architecture AI accelerator research (error)
- Fetch error: web_search returned no in-window results (cutoff 2025-10-04)

## Search: last 90 days GPU kernel fusion compiler matmul epilogue fusion ML training research (new: 1, showing: 1)
- [DPVO-QAT++: Heterogeneous QAT and CUDA Kernel Fusion for High-Performance Deep Patch Visual Odometry](https://arxiv.org/abs/2511.12653) — 2025-11-16
  - Authors: n/a
  - Affiliations: not provided
  - Proposes a heterogeneous quantization-aware training (QAT) pipeline for deep patch visual odometry, emphasizing GPU efficiency by reducing activation/weight precision while maintaining accuracy, lowering memory bandwidth pressure and footprint during training/inference.
  - Introduces custom CUDA kernel fusion for fake-quantization (e.g., fuse quantize/dequantize + scale/clip + adjacent ops) to cut kernel-launch overhead and intermediate tensor traffic, improving throughput on GPU.
  - GPU-relevant takeaway: performance gains primarily come from bandwidth/launch reductions rather than changing core GEMM/matmul math; any matmul-heavy blocks benefit indirectly via reduced surrounding overhead and better end-to-end pipeline utilization.

## Search: last 90 days AMD CDNA MI300 matrix multiplication MFMA WMMA research (error)
- Fetch error: web_search returned no in-window results (cutoff 2025-10-04)
