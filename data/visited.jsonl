{"url":"https://arxiv.org/abs/2209.02878v1","title":"GPU implementation of a ray-surface intersection algorithm in CUDA (Compute Unified Device Architecture)","source":"arXiv: GPU OR CUDA","published":"2022-09-07","fetched_at":"2025-12-22T16:47:23.150341903+00:00"}
{"url":"https://arxiv.org/abs/1906.08819v1","title":"Performance Comparison Between OpenCV Built in CPU and GPU Functions on Image Processing Operations","source":"arXiv: GPU OR CUDA","published":"2019-06-20","fetched_at":"2025-12-22T16:47:23.150362820+00:00"}
{"url":"https://arxiv.org/abs/2306.00358v2","title":"GPU-Acceleration of Tensor Renormalization with PyTorch using CUDA","source":"arXiv: GPU OR CUDA","published":"2023-06-01","fetched_at":"2025-12-22T16:47:23.150369866+00:00"}
{"url":"https://arxiv.org/abs/2503.08946v1","title":"SIMT/GPU Data Race Verification using ISCC and Intermediary Code Representations: A Case Study","source":"arXiv: GPU OR CUDA","published":"2025-03-11","fetched_at":"2025-12-22T16:47:23.150383200+00:00"}
{"url":"https://arxiv.org/abs/2512.02551v2","title":"CUDA-L2: Surpassing cuBLAS Performance for Matrix Multiplication through Reinforcement Learning","source":"arXiv: GPU OR CUDA","published":"2025-12-02","fetched_at":"2025-12-22T16:47:23.150390422+00:00"}
{"url":"https://arxiv.org/abs/2109.00673v1","title":"Supporting CUDA for an extended RISC-V GPU architecture","source":"arXiv: GPU OR CUDA","published":"2021-09-02","fetched_at":"2025-12-22T16:47:23.150397033+00:00"}
{"url":"https://arxiv.org/abs/0811.2111v1","title":"GPU computing for 2-d spin systems: CUDA vs OpenGL","source":"arXiv: GPU OR CUDA","published":"2008-11-13","fetched_at":"2025-12-22T16:47:23.150402755+00:00"}
{"url":"https://arxiv.org/abs/1412.1498v2","title":"Coulomb and Landau Gauge Fixing in GPUs using CUDA and MILC","source":"arXiv: GPU OR CUDA","published":"2014-12-03","fetched_at":"2025-12-22T16:47:23.150418505+00:00"}
{"url":"https://arxiv.org/abs/1305.7383v2","title":"CUDA Leaks: Information Leakage in GPU Architectures","source":"arXiv: GPU OR CUDA","published":"2013-05-31","fetched_at":"2025-12-22T16:47:23.150424987+00:00"}
{"url":"https://arxiv.org/abs/1312.5853v4","title":"Multi-GPU Training of ConvNets","source":"arXiv: GPU OR CUDA","published":"2013-12-20","fetched_at":"2025-12-22T16:47:23.150431459+00:00"}
{"url":"https://arxiv.org/abs/2406.16091v1","title":"Efficient GPU Implementation of Particle Interactions with Cutoff Radius and Few Particles per Cell","source":"arXiv: GPU OR CUDA","published":"2024-06-23","fetched_at":"2025-12-22T16:47:23.150436930+00:00"}
{"url":"https://arxiv.org/abs/2103.13937v4","title":"CUDA Tutorial -- Cryptanalysis of Classical Ciphers Using Modern GPUs and CUDA","source":"arXiv: GPU OR CUDA","published":"2021-03-25","fetched_at":"2025-12-22T16:47:23.150442606+00:00"}
{"url":"https://arxiv.org/abs/2501.05938v1","title":"ML-Based Optimum Number of CUDA Streams for the GPU Implementation of the Tridiagonal Partition Method","source":"arXiv: GPU OR CUDA","published":"2025-01-10","fetched_at":"2025-12-22T16:47:23.150447976+00:00"}
{"url":"https://arxiv.org/abs/1801.03138v1","title":"Deep In-GPU Experience Replay","source":"arXiv: GPU OR CUDA","published":"2018-01-09","fetched_at":"2025-12-22T16:47:23.150469745+00:00"}
{"url":"https://arxiv.org/abs/1112.4533v4","title":"Generating SU(Nc) pure gauge lattice QCD configurations on GPUs with CUDA","source":"arXiv: GPU OR CUDA","published":"2011-12-20","fetched_at":"2025-12-22T16:47:23.150494245+00:00"}
{"url":"https://arxiv.org/abs/1305.4376v1","title":"3DES ECB Optimized for Massively Parallel CUDA GPU Architecture","source":"arXiv: GPU OR CUDA","published":"2013-05-19","fetched_at":"2025-12-22T16:47:23.150499837+00:00"}
{"url":"https://arxiv.org/abs/2207.12116v1","title":"A Variant of Concurrent Constraint Programming on GPU","source":"arXiv: GPU OR CUDA","published":"2022-07-18","fetched_at":"2025-12-22T16:47:23.150506365+00:00"}
{"url":"https://arxiv.org/abs/1808.01309v1","title":"GPU parallelization of a hybrid pseudospectral fluid turbulence framework using CUDA","source":"arXiv: GPU OR CUDA","published":"2018-08-03","fetched_at":"2025-12-22T16:47:23.150513504+00:00"}
{"url":"https://arxiv.org/abs/1204.6193v1","title":"Random number generators for massively parallel simulations on GPU","source":"arXiv: GPU OR CUDA","published":"2012-04-27","fetched_at":"2025-12-22T16:47:23.150518800+00:00"}
{"url":"https://arxiv.org/abs/1810.08137v3","title":"Performance Comparison on Parallel CPU and GPU Algorithms for Unified Gas-Kinetic Scheme","source":"arXiv: GPU OR CUDA","published":"2018-10-18","fetched_at":"2025-12-22T16:47:23.150524625+00:00"}
{"url":"https://arxiv.org/abs/1602.08735v2","title":"Heuristics for the Variable Sized Bin Packing Problem Using a Hybrid P-System and CUDA Architecture","source":"arXiv: GPU OR CUDA","published":"2016-02-28","fetched_at":"2025-12-22T16:47:23.150529847+00:00"}
{"url":"https://arxiv.org/abs/1711.01919v1","title":"Fast Integral Histogram Computations on GPU for Real-Time Video Analytics","source":"arXiv: GPU OR CUDA","published":"2017-11-06","fetched_at":"2025-12-22T16:47:23.150534967+00:00"}
{"url":"https://arxiv.org/abs/2309.09609v2","title":"Comparing Performance and Portability between CUDA and SYCL for Protein Database Search on NVIDIA, AMD, and Intel GPUs","source":"arXiv: GPU OR CUDA","published":"2023-09-18","fetched_at":"2025-12-22T16:47:23.150540217+00:00"}
{"url":"https://arxiv.org/abs/2102.12739v1","title":"Implementation of 3D degridding algorithm on the NVIDIA GPUs using CUDA","source":"arXiv: GPU OR CUDA","published":"2021-02-25","fetched_at":"2025-12-22T16:47:23.150545337+00:00"}
{"url":"https://arxiv.org/abs/1701.01170v1","title":"Gunrock: GPU Graph Analytics","source":"arXiv: GPU OR CUDA","published":"2017-01-04","fetched_at":"2025-12-22T16:47:23.150550643+00:00"}
{"url":"https://arxiv.org/abs/2501.09398v1","title":"Boosting Performance of Iterative Applications on GPUs: Kernel Batching with CUDA Graphs","source":"arXiv: GPU OR CUDA","published":"2025-01-16","fetched_at":"2025-12-22T16:47:23.150555930+00:00"}
{"url":"https://arxiv.org/abs/2010.14416v1","title":"Multi-GPU implementation of a time-explicit finite volume solver for the Shallow-Water Equations using CUDA and a CUDA-Aware version of OpenMPI","source":"arXiv: GPU OR CUDA","published":"2020-10-27","fetched_at":"2025-12-22T16:47:23.150561671+00:00"}
{"url":"https://arxiv.org/abs/1012.2270v1","title":"New Row-grouped CSR format for storing the sparse matrices on GPU with implementation in CUDA","source":"arXiv: GPU OR CUDA","published":"2010-12-10","fetched_at":"2025-12-22T16:47:23.150566745+00:00"}
{"url":"https://arxiv.org/abs/2505.19467v1","title":"GPU acceleration of non-equilibrium Green's function calculation using OpenACC and CUDA FORTRAN","source":"arXiv: GPU OR CUDA","published":"2025-05-26","fetched_at":"2025-12-22T16:47:23.150609060+00:00"}
{"url":"https://arxiv.org/abs/2507.14111v9","title":"CUDA-L1: Improving CUDA Optimization via Contrastive Reinforcement Learning","source":"arXiv: GPU OR CUDA","published":"2025-07-18","fetched_at":"2025-12-22T16:47:23.150614300+00:00"}
{"url":"https://arxiv.org/abs/1006.4644v1","title":"cuInspiral: prototype gravitational waves detection pipeline fully coded on GPU using CUDA","source":"arXiv: GPU OR CUDA","published":"2010-06-16","fetched_at":"2025-12-22T16:47:23.150619615+00:00"}
{"url":"https://arxiv.org/abs/2110.08221v2","title":"Metrics and Design of an Instruction Roofline Model for AMD GPUs","source":"arXiv: GPU OR CUDA","published":"2021-10-15","fetched_at":"2025-12-22T16:47:23.150624708+00:00"}
{"url":"https://arxiv.org/abs/1005.2581v3","title":"A Performance Comparison of CUDA and OpenCL","source":"arXiv: GPU OR CUDA","published":"2010-05-14","fetched_at":"2025-12-22T16:47:23.150629939+00:00"}
{"url":"https://arxiv.org/abs/1202.4347v1","title":"GPGPU Processing in CUDA Architecture","source":"arXiv: GPU OR CUDA","published":"2012-02-20","fetched_at":"2025-12-22T16:47:23.150636549+00:00"}
{"url":"https://arxiv.org/abs/1304.7863v1","title":"ACL2 Meets the GPU: Formalizing a CUDA-based Parallelizable All-Pairs Shortest Path Algorithm in ACL2","source":"arXiv: GPU OR CUDA","published":"2013-04-30","fetched_at":"2025-12-22T16:47:23.150641818+00:00"}
{"url":"https://arxiv.org/abs/1403.7560v1","title":"CUDA programs for GPU computing of Swendsen-Wang multi-cluster spin flip algorithm: 2D and 3D Ising, Potts, and XY models","source":"arXiv: GPU OR CUDA","published":"2014-03-28","fetched_at":"2025-12-22T16:47:23.150646901+00:00"}
{"url":"https://arxiv.org/abs/1705.01598v1","title":"cuTT: A High-Performance Tensor Transpose Library for CUDA Compatible GPUs","source":"arXiv: GPU OR CUDA","published":"2017-05-03","fetched_at":"2025-12-22T16:47:23.150651864+00:00"}
{"url":"https://arxiv.org/abs/2006.14290v1","title":"Preparing Ginkgo for AMD GPUs -- A Testimonial on Porting CUDA Code to HIP","source":"arXiv: GPU OR CUDA","published":"2020-06-25","fetched_at":"2025-12-22T16:47:23.150657281+00:00"}
{"url":"https://arxiv.org/abs/2206.07896v1","title":"CuPBoP: CUDA for Parallelized and Broad-range Processors","source":"arXiv: GPU OR CUDA","published":"2022-06-16","fetched_at":"2025-12-22T16:47:23.150663235+00:00"}
{"url":"https://arxiv.org/abs/2507.19723v1","title":"Accelerating Matrix Multiplication: A Performance Comparison Between Multi-Core CPU and GPU","source":"arXiv: GPU OR CUDA","published":"2025-07-26","fetched_at":"2025-12-22T16:47:23.150668457+00:00"}
{"url":"https://arxiv.org/abs/1609.01567v2","title":"OpenCL/CUDA algorithms for parallel decoding of any irregular LDPC code using GPU","source":"arXiv: GPU OR CUDA","published":"2016-09-06","fetched_at":"2025-12-22T16:47:23.150673661+00:00"}
{"url":"https://arxiv.org/abs/1211.0582v1","title":"High-Order Discontinuous Galerkin Methods by GPU Metaprogramming","source":"arXiv: GPU OR CUDA","published":"2012-11-02","fetched_at":"2025-12-22T16:47:23.150678679+00:00"}
{"url":"https://arxiv.org/abs/1607.05707v1","title":"Lowering IrGL to CUDA","source":"arXiv: GPU OR CUDA","published":"2016-07-19","fetched_at":"2025-12-22T16:47:23.150683781+00:00"}
{"url":"https://arxiv.org/abs/2506.09092v1","title":"CUDA-LLM: LLMs Can Write Efficient CUDA Kernels","source":"arXiv: GPU OR CUDA","published":"2025-06-10","fetched_at":"2025-12-22T16:47:23.150688911+00:00"}
{"url":"https://arxiv.org/abs/2510.02894v1","title":"PyRadiomics-cuda: a GPU-accelerated 3D features extraction from medical images within PyRadiomics","source":"arXiv: GPU OR CUDA","published":"2025-10-03","fetched_at":"2025-12-22T16:47:23.150693883+00:00"}
{"url":"https://arxiv.org/abs/2503.19779v2","title":"PyGraph: Robust Compiler Support for CUDA Graphs in PyTorch","source":"arXiv: GPU OR CUDA","published":"2025-03-25","fetched_at":"2025-12-22T16:47:23.150699059+00:00"}
{"url":"https://arxiv.org/abs/1905.01833v3","title":"Characterizing and Detecting CUDA Program Bugs","source":"arXiv: GPU OR CUDA","published":"2019-05-06","fetched_at":"2025-12-22T16:47:23.150704559+00:00"}
{"url":"https://arxiv.org/abs/1401.6047v3","title":"Finite difference numerical method for the superlattice Boltzmann transport equation and case comparison of CPU(C) and GPU(CUDA) implementations","source":"arXiv: GPU OR CUDA","published":"2014-01-23","fetched_at":"2025-12-22T16:47:23.150709670+00:00"}
{"url":"https://arxiv.org/abs/2008.10596v1","title":"CRAC: Checkpoint-Restart Architecture for CUDA with Streams and UVM","source":"arXiv: GPU OR CUDA","published":"2020-08-24","fetched_at":"2025-12-22T16:47:23.150714744+00:00"}
{"url":"https://arxiv.org/abs/1909.07439v2","title":"Bonsai-SPH: A GPU accelerated astrophysical Smoothed Particle Hydrodynamics code","source":"arXiv: GPU OR CUDA","published":"2019-09-16","fetched_at":"2025-12-22T16:47:23.150719883+00:00"}
{"url":"https://arxiv.org/abs/2005.09148v1","title":"Out-of-Core GPU Gradient Boosting","source":"arXiv: ML + GPU","published":"2020-05-19","fetched_at":"2025-12-22T16:47:24.223691750+00:00"}
{"url":"https://arxiv.org/abs/2212.07936v1","title":"A Study on the Intersection of GPU Utilization and CNN Inference","source":"arXiv: ML + GPU","published":"2022-12-15","fetched_at":"2025-12-22T16:47:24.223707860+00:00"}
{"url":"https://arxiv.org/abs/2511.02132v1","title":"Optimizing Attention on GPUs by Exploiting GPU Architectural NUMA Effects","source":"arXiv: ML + GPU","published":"2025-11-03","fetched_at":"2025-12-22T16:47:24.223714462+00:00"}
{"url":"https://arxiv.org/abs/2104.02188v1","title":"GPU Domain Specialization via Composable On-Package Architecture","source":"arXiv: ML + GPU","published":"2021-04-05","fetched_at":"2025-12-22T16:47:24.223720796+00:00"}
{"url":"https://arxiv.org/abs/1902.04610v1","title":"Salus: Fine-Grained GPU Sharing Primitives for Deep Learning Applications","source":"arXiv: ML + GPU","published":"2019-02-12","fetched_at":"2025-12-22T16:47:24.223729573+00:00"}
{"url":"https://arxiv.org/abs/2209.06018v3","title":"An Analysis of Collocation on GPUs for Deep Learning Training","source":"arXiv: ML + GPU","published":"2022-09-13","fetched_at":"2025-12-22T16:47:24.223736027+00:00"}
{"url":"https://arxiv.org/abs/1706.08359v1","title":"GPU-acceleration for Large-scale Tree Boosting","source":"arXiv: ML + GPU","published":"2017-06-26","fetched_at":"2025-12-22T16:47:24.223836407+00:00"}
{"url":"https://arxiv.org/abs/1806.11248v1","title":"XGBoost: Scalable GPU Accelerated Learning","source":"arXiv: ML + GPU","published":"2018-06-29","fetched_at":"2025-12-22T16:47:24.223842545+00:00"}
{"url":"https://arxiv.org/abs/2112.04800v1","title":"GPU backed Data Mining on Android Devices","source":"arXiv: ML + GPU","published":"2021-12-09","fetched_at":"2025-12-22T16:47:24.223849286+00:00"}
{"url":"https://arxiv.org/abs/2404.14527v4","title":"Mélange: Cost Efficient Large Language Model Serving by Exploiting GPU Heterogeneity","source":"arXiv: ML + GPU","published":"2024-04-22","fetched_at":"2025-12-22T16:47:24.223855481+00:00"}
{"url":"https://arxiv.org/abs/2203.16340v1","title":"Optimization for Classical Machine Learning Problems on the GPU","source":"arXiv: ML + GPU","published":"2022-03-30","fetched_at":"2025-12-22T16:47:24.223861203+00:00"}
{"url":"https://arxiv.org/abs/2012.02732v1","title":"Nimble: Lightweight and Parallel GPU Task Scheduling for Deep Learning","source":"arXiv: ML + GPU","published":"2020-12-04","fetched_at":"2025-12-22T16:47:24.223867286+00:00"}
{"url":"https://arxiv.org/abs/1907.08467v2","title":"Accelerating Reinforcement Learning through GPU Atari Emulation","source":"arXiv: ML + GPU","published":"2019-07-19","fetched_at":"2025-12-22T16:47:24.223872907+00:00"}
{"url":"https://arxiv.org/abs/2512.07853v1","title":"GPU Memory Prediction for Multimodal Model Training","source":"arXiv: ML + GPU","published":"2025-11-26","fetched_at":"2025-12-22T16:47:24.223879268+00:00"}
{"url":"https://arxiv.org/abs/2404.10933v1","title":"LLMem: Estimating GPU Memory Usage for Fine-Tuning Pre-Trained LLMs","source":"arXiv: ML + GPU","published":"2024-04-16","fetched_at":"2025-12-22T16:47:24.223885184+00:00"}
{"url":"https://arxiv.org/abs/2202.13481v1","title":"PARIS and ELSA: An Elastic Scheduling Algorithm for Reconfigurable Multi-GPU Inference Servers","source":"arXiv: ML + GPU","published":"2022-02-27","fetched_at":"2025-12-22T16:47:24.223895036+00:00"}
{"url":"https://arxiv.org/abs/2410.07192v1","title":"PipeFill: Using GPUs During Bubbles in Pipeline-parallel LLM Training","source":"arXiv: ML + GPU","published":"2024-09-23","fetched_at":"2025-12-22T16:47:24.223901545+00:00"}
{"url":"https://arxiv.org/abs/2504.15465v1","title":"LithOS: An Operating System for Efficient Machine Learning on GPUs","source":"arXiv: ML + GPU","published":"2025-04-21","fetched_at":"2025-12-22T16:47:24.223907072+00:00"}
{"url":"https://arxiv.org/abs/2407.13853v3","title":"Forecasting GPU Performance for Deep Learning Training and Inference","source":"arXiv: ML + GPU","published":"2024-07-18","fetched_at":"2025-12-22T16:47:24.223912332+00:00"}
{"url":"https://arxiv.org/abs/1404.1521v3","title":"Exploring the power of GPU's for training Polyglot language models","source":"arXiv: ML + GPU","published":"2014-04-05","fetched_at":"2025-12-22T16:47:24.223917896+00:00"}
{"url":"https://arxiv.org/abs/2104.10949v1","title":"CryptGPU: Fast Privacy-Preserving Machine Learning on the GPU","source":"arXiv: ML + GPU","published":"2021-04-22","fetched_at":"2025-12-22T16:47:24.223923248+00:00"}
{"url":"https://arxiv.org/abs/2005.04347v1","title":"GPU Acceleration of Sparse Neural Networks","source":"arXiv: ML + GPU","published":"2020-05-09","fetched_at":"2025-12-22T16:47:24.223928313+00:00"}
{"url":"https://arxiv.org/abs/2012.04210v1","title":"The Architectural Implications of Distributed Reinforcement Learning on CPU-GPU Systems","source":"arXiv: ML + GPU","published":"2020-12-08","fetched_at":"2025-12-22T16:47:24.223933359+00:00"}
{"url":"https://arxiv.org/abs/2503.24230v1","title":"GPU-centric Communication Schemes for HPC and ML Applications","source":"arXiv: ML + GPU","published":"2025-03-31","fetched_at":"2025-12-22T16:47:24.223938711+00:00"}
{"url":"https://arxiv.org/abs/2411.01142v1","title":"NEO: Saving GPU Memory Crisis with CPU Offloading for Online LLM Inference","source":"arXiv: ML + GPU","published":"2024-11-02","fetched_at":"2025-12-22T16:47:24.223943720+00:00"}
{"url":"https://arxiv.org/abs/1901.10008v2","title":"The OoO VLIW JIT Compiler for GPU Inference","source":"arXiv: ML + GPU","published":"2019-01-28","fetched_at":"2025-12-22T16:47:24.223948887+00:00"}
{"url":"https://arxiv.org/abs/2311.10359v5","title":"FIKIT: Priority-Based Real-time GPU Multi-tasking Scheduling with Kernel Identification","source":"arXiv: ML + GPU","published":"2023-11-17","fetched_at":"2025-12-22T16:47:24.223954137+00:00"}
{"url":"https://arxiv.org/abs/2310.09443v1","title":"G10: Enabling An Efficient Unified GPU Memory and Storage Architecture with Smart Tensor Migrations","source":"arXiv: ML + GPU","published":"2023-10-13","fetched_at":"2025-12-22T16:47:24.223959350+00:00"}
{"url":"https://arxiv.org/abs/1511.08228v3","title":"Neural GPUs Learn Algorithms","source":"arXiv: ML + GPU","published":"2015-11-25","fetched_at":"2025-12-22T16:47:24.223964350+00:00"}
{"url":"https://arxiv.org/abs/2509.15815v2","title":"GPU Temperature Simulation-Based Testing for In-Vehicle Deep Learning Frameworks","source":"arXiv: ML + GPU","published":"2025-09-19","fetched_at":"2025-12-22T16:47:24.223969878+00:00"}
{"url":"https://arxiv.org/abs/2003.13630v3","title":"TResNet: High Performance GPU-Dedicated Architecture","source":"arXiv: ML + GPU","published":"2020-03-30","fetched_at":"2025-12-22T16:47:24.223975341+00:00"}
{"url":"https://arxiv.org/abs/2512.09472v1","title":"WarmServe: Enabling One-for-Many GPU Prewarming for Multi-LLM Serving","source":"arXiv: ML + GPU","published":"2025-12-10","fetched_at":"2025-12-22T16:47:24.223980841+00:00"}
{"url":"https://arxiv.org/abs/2310.19816v1","title":"Benchmarking GPUs on SVBRDF Extractor Model","source":"arXiv: ML + GPU","published":"2023-10-19","fetched_at":"2025-12-22T16:47:24.223986119+00:00"}
{"url":"https://arxiv.org/abs/2312.12456v2","title":"PowerInfer: Fast Large Language Model Serving with a Consumer-grade GPU","source":"arXiv: ML + GPU","published":"2023-12-16","fetched_at":"2025-12-22T16:47:24.223991841+00:00"}
{"url":"https://arxiv.org/abs/2109.11067v1","title":"Serving DNN Models with Multi-Instance GPUs: A Case of the Reconfigurable Machine Scheduling Problem","source":"arXiv: ML + GPU","published":"2021-09-18","fetched_at":"2025-12-22T16:47:24.223997424+00:00"}
{"url":"https://arxiv.org/abs/2410.11855v1","title":"Online Energy Optimization in GPUs: A Multi-Armed Bandit Approach","source":"arXiv: ML + GPU","published":"2024-10-03","fetched_at":"2025-12-22T16:47:24.224002628+00:00"}
{"url":"https://arxiv.org/abs/2002.09481v1","title":"TFApprox: Towards a Fast Emulation of DNN Approximate Hardware Accelerators on GPU","source":"arXiv: ML + GPU","published":"2020-02-21","fetched_at":"2025-12-22T16:47:24.224007841+00:00"}
{"url":"https://arxiv.org/abs/2501.08071v1","title":"CuAsmRL: Optimizing GPU SASS Schedules via Deep Reinforcement Learning","source":"arXiv: ML + GPU","published":"2025-01-14","fetched_at":"2025-12-22T16:47:24.224013007+00:00"}
{"url":"https://arxiv.org/abs/2201.11853v1","title":"Prediction of GPU Failures Under Deep Learning Workloads","source":"arXiv: ML + GPU","published":"2022-01-27","fetched_at":"2025-12-22T16:47:24.224018711+00:00"}
{"url":"https://arxiv.org/abs/2004.08771v1","title":"Heterogeneous CPU+GPU Stochastic Gradient Descent Algorithms","source":"arXiv: ML + GPU","published":"2020-04-19","fetched_at":"2025-12-22T16:47:24.224023878+00:00"}
{"url":"https://arxiv.org/abs/2309.02521v3","title":"Comparative Analysis of CPU and GPU Profiling for Deep Learning Models","source":"arXiv: ML + GPU","published":"2023-09-05","fetched_at":"2025-12-22T16:47:24.224030313+00:00"}
{"url":"https://arxiv.org/abs/1811.12174v1","title":"Data-parallel distributed training of very large models beyond GPU capacity","source":"arXiv: ML + GPU","published":"2018-11-29","fetched_at":"2025-12-22T16:47:24.224035933+00:00"}
{"url":"https://arxiv.org/abs/2502.10439v1","title":"Crypto Miner Attack: GPU Remote Code Execution Attacks","source":"arXiv: ML + GPU","published":"2025-02-09","fetched_at":"2025-12-22T16:47:24.224041063+00:00"}
{"url":"https://arxiv.org/abs/2110.10049v1","title":"Boosting Graph Embedding on a Single GPU","source":"arXiv: ML + GPU","published":"2021-10-19","fetched_at":"2025-12-22T16:47:24.224046693+00:00"}
{"url":"https://arxiv.org/abs/2311.13225v2","title":"NeutronOrch: Rethinking Sample-based GNN Training under CPU-GPU Heterogeneous Environments","source":"arXiv: ML + GPU","published":"2023-11-22","fetched_at":"2025-12-22T16:47:24.224052165+00:00"}
{"url":"https://arxiv.org/abs/2211.13939v2","title":"Efficient Incremental Text-to-Speech on GPUs","source":"arXiv: ML + GPU","published":"2022-11-25","fetched_at":"2025-12-22T16:47:24.224057711+00:00"}
{"url":"https://arxiv.org/abs/1410.4984v1","title":"Gaussian Process Models with Parallelization and GPU acceleration","source":"arXiv: ML + GPU","published":"2014-10-18","fetched_at":"2025-12-22T16:47:24.224062841+00:00"}
{"url":"https://arxiv.org/abs/2507.06608v5","title":"Nexus:Proactive Intra-GPU Disaggregation of Prefill and Decode in LLM Serving","source":"arXiv: ML + GPU","published":"2025-07-09","fetched_at":"2025-12-22T16:47:24.224068480+00:00"}
{"url":"https://arxiv.org/abs/2402.07033v3","title":"Fiddler: CPU-GPU Orchestration for Fast Inference of Mixture-of-Experts Models","source":"arXiv: ML + GPU","published":"2024-02-10","fetched_at":"2025-12-22T16:47:24.224074230+00:00"}
{"url":"https://developer.nvidia.com/blog/accelerating-ai-powered-chemistry-and-materials-science-simulations-with-nvidia-alchemi-toolkit-ops/","title":"Accelerating AI-Powered Chemistry and Materials Science Simulations with NVIDIA ALCHEMI Toolkit-Ops","source":"NVIDIA Developer Blog","published":"2025-12-19","fetched_at":"2025-12-22T16:47:34.869628991+00:00"}
{"url":"https://developer.nvidia.com/blog/real-time-decoding-algorithmic-gpu-decoders-and-ai-inference-enhancements-in-nvidia-cuda-q-qec/","title":"Real-Time Decoding, Algorithmic GPU Decoders, and AI Inference Enhancements in NVIDIA CUDA-Q QEC","source":"NVIDIA Developer Blog","published":"2025-12-17","fetched_at":"2025-12-22T16:47:34.869645491+00:00"}
{"url":"https://developer.nvidia.com/blog/migrate-apache-spark-workloads-to-gpus-at-scale-on-amazon-emr-with-project-aether/","title":"Migrate Apache Spark Workloads to GPUs at Scale on Amazon EMR with Project Aether","source":"NVIDIA Developer Blog","published":"2025-12-17","fetched_at":"2025-12-22T16:47:34.869651296+00:00"}
{"url":"https://developer.nvidia.com/blog/solving-large-scale-linear-sparse-problems-with-nvidia-cudss/","title":"Solving Large-Scale Linear Sparse Problems with NVIDIA cuDSS","source":"NVIDIA Developer Blog","published":"2025-12-17","fetched_at":"2025-12-22T16:47:34.869657019+00:00"}
{"url":"https://developer.nvidia.com/blog/simulate-robotic-environments-faster-with-nvidia-isaac-sim-and-world-labs-marble/","title":"Simulate Robotic Environments Faster with NVIDIA Isaac Sim and World Labs Marble","source":"NVIDIA Developer Blog","published":"2025-12-17","fetched_at":"2025-12-22T16:47:34.869667389+00:00"}
{"url":"https://developer.nvidia.com/blog/using-ai-physics-for-technology-computer-aided-design-simulations/","title":"Using AI Physics for Technology Computer-Aided Design Simulations","source":"NVIDIA Developer Blog","published":"2025-12-17","fetched_at":"2025-12-22T16:47:34.869672695+00:00"}
{"url":"https://developer.nvidia.com/blog/simulate-an-accurate-radio-environment-using-nvidia-aerial-omniverse-digital-twin/","title":"Simulate an Accurate Radio Environment Using NVIDIA Aerial Omniverse Digital Twin","source":"NVIDIA Developer Blog","published":"2025-12-17","fetched_at":"2025-12-22T16:47:34.869677852+00:00"}
{"url":"https://developer.nvidia.com/blog/optimizing-semiconductor-defect-classification-with-generative-ai-and-vision-foundation-models/","title":"Optimizing Semiconductor Defect Classification with Generative AI and Vision Foundation Models","source":"NVIDIA Developer Blog","published":"2025-12-17","fetched_at":"2025-12-22T16:47:34.869683093+00:00"}
{"url":"https://developer.nvidia.com/blog/accelerating-long-context-inference-with-skip-softmax-in-nvidia-tensorrt-llm/","title":"Accelerating Long-Context Inference with Skip Softmax in NVIDIA TensorRT-LLM","source":"NVIDIA Developer Blog","published":"2025-12-16","fetched_at":"2025-12-22T16:47:34.869689704+00:00"}
{"url":"https://developer.nvidia.com/blog/advanced-large-scale-quantum-simulation-techniques-in-cuquantum-sdk-v25-11/","title":"Advanced Large-Scale Quantum Simulation Techniques in cuQuantum SDK v25.11","source":"NVIDIA Developer Blog","published":"2025-12-16","fetched_at":"2025-12-22T16:47:34.869695769+00:00"}
{"url":"https://developer.nvidia.com/blog/ai-factories-physical-ai-and-advances-in-models-agents-and-infrastructure-that-shaped-2025/","title":"AI Factories, Physical AI, and Advances in Models, Agents, and Infrastructure That Shaped 2025","source":"NVIDIA Developer Blog","published":"2025-12-16","fetched_at":"2025-12-22T16:47:34.869701074+00:00"}
{"url":"https://developer.nvidia.com/blog/boost-gpu-memory-performance-with-no-code-changes-using-nvidia-cuda-mps/","title":"Boost GPU Memory Performance with No Code Changes Using NVIDIA CUDA MPS","source":"NVIDIA Developer Blog","published":"2025-12-16","fetched_at":"2025-12-22T16:47:34.869706278+00:00"}
{"url":"https://developer.nvidia.com/blog/delivering-flexible-performance-for-future-ready-data-centers-with-nvidia-mgx/","title":"Delivering Flexible Performance for Future-Ready Data Centers with NVIDIA MGX","source":"NVIDIA Developer Blog","published":"2025-12-15","fetched_at":"2025-12-22T16:47:34.869712241+00:00"}
{"url":"https://developer.nvidia.com/blog/reducing-cuda-binary-size-to-distribute-cuml-on-pypi/","title":"Reducing CUDA Binary Size to Distribute cuML on PyPI","source":"NVIDIA Developer Blog","published":"2025-12-15","fetched_at":"2025-12-22T16:47:34.869848351+00:00"}
{"url":"https://developer.nvidia.com/blog/nvidia-gpu-accelerated-sirius-achieves-record-setting-clickbench-record/","title":"NVIDIA CUDA-X Powers the New Sirius GPU Engine for DuckDB, Setting ClickBench Records","source":"NVIDIA Developer Blog","published":"2025-12-15","fetched_at":"2025-12-22T16:47:34.869852925+00:00"}
{"url":"https://developer.nvidia.com/blog/inside-nvidia-nemotron-3-techniques-tools-and-data-that-make-it-efficient-and-accurate/","title":"Inside NVIDIA Nemotron 3: Techniques, Tools, and Data That Make It Efficient and Accurate","source":"NVIDIA Developer Blog","published":"2025-12-15","fetched_at":"2025-12-22T16:47:34.869857925+00:00"}
{"url":"https://developer.nvidia.com/blog/how-to-train-scientific-agents-with-reinforcement-learning/","title":"How to Train Scientific Agents with Reinforcement Learning","source":"NVIDIA Developer Blog","published":"2025-12-15","fetched_at":"2025-12-22T16:47:34.869863703+00:00"}
{"url":"https://developer.nvidia.com/blog/enabling-horizontal-autoscaling-of-enterprise-rag-components-on-kubernetes/","title":"Enabling Horizontal Autoscaling of Enterprise RAG Components on Kubernetes","source":"NVIDIA Developer Blog","published":"2025-12-12","fetched_at":"2025-12-22T16:47:34.869868129+00:00"}
{"url":"https://developer.nvidia.com/blog/how-to-scale-fast-fourier-transforms-to-exascale-on-modern-nvidia-gpu-architectures/","title":"How to Scale Fast Fourier Transforms to Exascale on Modern NVIDIA GPU Architectures","source":"NVIDIA Developer Blog","published":"2025-12-12","fetched_at":"2025-12-22T16:47:34.869873499+00:00"}
{"url":"https://developer.nvidia.com/blog/r2d2-improving-robot-manipulation-with-simulation-and-language-models/","title":"R²D²: Improving Robot Manipulation with Simulation and Language Models","source":"NVIDIA Developer Blog","published":"2025-12-12","fetched_at":"2025-12-22T16:47:34.869877564+00:00"}
{"url":"https://developer.nvidia.com/blog/how-to-build-privacy-preserving-evaluation-benchmarks-with-synthetic-data/","title":"How to Build Privacy-Preserving Evaluation Benchmarks with Synthetic Data","source":"NVIDIA Developer Blog","published":"2025-12-12","fetched_at":"2025-12-22T16:47:34.869881583+00:00"}
{"url":"https://developer.nvidia.com/blog/nvidia-blackwell-enables-3x-faster-training-and-nearly-2x-training-performance-per-dollar-than-previous-gen-architecture/","title":"NVIDIA Blackwell Enables 3x Faster Training and Nearly 2x Training Performance Per Dollar than Previous-Gen Architecture","source":"NVIDIA Developer Blog","published":"2025-12-11","fetched_at":"2025-12-22T16:47:34.869886166+00:00"}
{"url":"https://developer.nvidia.com/blog/next-generation-ai-factory-telemetry-with-nvidia-spectrum-x-ethernet/","title":"Next-Generation AI Factory Telemetry with NVIDIA Spectrum-X Ethernet","source":"NVIDIA Developer Blog","published":"2025-12-11","fetched_at":"2025-12-22T16:47:34.869890221+00:00"}
{"url":"https://developer.nvidia.com/blog/getting-started-with-edge-ai-on-nvidia-jetson-llms-vlms-and-foundation-models-for-robotics/","title":"Getting Started with Edge AI on NVIDIA Jetson: LLMs, VLMs, and Foundation Models for Robotics","source":"NVIDIA Developer Blog","published":"2025-12-11","fetched_at":"2025-12-22T16:47:34.869895046+00:00"}
{"url":"https://developer.nvidia.com/blog/enhancing-communication-observability-of-ai-workloads-with-nccl-inspector/","title":"Enhancing Communication Observability of AI Workloads with NCCL Inspector","source":"NVIDIA Developer Blog","published":"2025-12-10","fetched_at":"2025-12-22T16:47:34.869899175+00:00"}
{"url":"https://developer.nvidia.com/blog/better-bug-detection-how-compile-time-instrumentation-for-compute-sanitizer-enhances-memory-safety/","title":"Better Bug Detection: How Compile-Time Instrumentation for Compute Sanitizer Enhances Memory Safety","source":"NVIDIA Developer Blog","published":"2025-12-10","fetched_at":"2025-12-22T16:47:34.869903620+00:00"}
{"url":"https://developer.nvidia.com/blog/top-5-ai-model-optimization-techniques-for-faster-smarter-inference/","title":"Top 5 AI Model Optimization Techniques for Faster, Smarter Inference","source":"NVIDIA Developer Blog","published":"2025-12-09","fetched_at":"2025-12-22T16:47:34.869907629+00:00"}
{"url":"https://developer.nvidia.com/blog/improve-ai-native-6g-design-with-the-nvidia-aerial-omniverse-digital-twin/","title":"Improve AI-Native 6G Design with the NVIDIA Aerial Omniverse Digital Twin","source":"NVIDIA Developer Blog","published":"2025-12-09","fetched_at":"2025-12-22T16:47:34.869911916+00:00"}
{"url":"https://developer.nvidia.com/blog/automate-kubernetes-ai-cluster-health-with-nvsentinel/","title":"Automate Kubernetes AI Cluster Health with NVSentinel","source":"NVIDIA Developer Blog","published":"2025-12-08","fetched_at":"2025-12-22T16:47:34.869915823+00:00"}
{"url":"https://developer.nvidia.com/blog/optimizing-inference-for-long-context-and-large-batch-sizes-with-nvfp4-kv-cache/","title":"Optimizing Inference for Long Context and Large Batch Sizes with NVFP4 KV Cache","source":"NVIDIA Developer Blog","published":"2025-12-08","fetched_at":"2025-12-22T16:47:34.869919981+00:00"}
{"url":"https://developer.nvidia.com/blog/nvidia-kaggle-grandmasters-win-artificial-general-intelligence-competition/","title":"NVIDIA Kaggle Grandmasters Win Artificial General Intelligence Competition","source":"NVIDIA Developer Blog","published":"2025-12-05","fetched_at":"2025-12-22T16:47:34.869926675+00:00"}
{"url":"https://developer.nvidia.com/blog/nvidia-grace-cpu-delivers-high-bandwidth-and-efficiency-for-modern-data-centers/","title":"NVIDIA Grace CPU Delivers High Bandwidth and Efficiency for Modern Data Centers","source":"NVIDIA Developer Blog","published":"2025-12-05","fetched_at":"2025-12-22T16:47:34.869931305+00:00"}
{"url":"https://developer.nvidia.com/blog/nvidia-cuda-13-1-powers-next-gen-gpu-programming-with-nvidia-cuda-tile-and-performance-gains/","title":"NVIDIA CUDA 13.1 Powers Next-Gen GPU Programming with NVIDIA CUDA Tile and Performance Gains","source":"NVIDIA Developer Blog","published":"2025-12-04","fetched_at":"2025-12-22T16:47:34.869936083+00:00"}
{"url":"https://developer.nvidia.com/blog/simplify-gpu-programming-with-nvidia-cuda-tile-in-python/","title":"Simplify GPU Programming with NVIDIA CUDA Tile in Python","source":"NVIDIA Developer Blog","published":"2025-12-04","fetched_at":"2025-12-22T16:47:34.869940092+00:00"}
{"url":"https://developer.nvidia.com/blog/focus-on-your-algorithm-nvidia-cuda-tile-handles-the-hardware/","title":"Focus on Your Algorithm—NVIDIA CUDA Tile Handles the Hardware","source":"NVIDIA Developer Blog","published":"2025-12-04","fetched_at":"2025-12-22T16:47:34.869944277+00:00"}
{"url":"https://developer.nvidia.com/blog/optimize-data-center-efficiency-for-ai-and-hpc-workloads-with-power-profiles/","title":"Optimize Data Center Efficiency for AI and HPC Workloads with Power Profiles","source":"NVIDIA Developer Blog","published":"2025-12-04","fetched_at":"2025-12-22T16:47:34.869948907+00:00"}
{"url":"https://developer.nvidia.com/blog/how-to-enhance-3d-gaussian-reconstruction-quality-for-simulation/","title":"How to Enhance 3D Gaussian Reconstruction Quality for Simulation","source":"NVIDIA Developer Blog","published":"2025-12-03","fetched_at":"2025-12-22T16:47:34.869952981+00:00"}
{"url":"https://developer.nvidia.com/blog/accelerating-real-time-financial-decisions-with-quantitative-portfolio-optimization/","title":"Accelerating Real-Time Financial Decisions with Quantitative Portfolio Optimization","source":"NVIDIA Developer Blog","published":"2025-12-02","fetched_at":"2025-12-22T16:47:34.869957731+00:00"}
{"url":"https://developer.nvidia.com/blog/nvidia-accelerated-mistral-3-open-models-deliver-efficiency-accuracy-at-any-scale/","title":"NVIDIA-Accelerated Mistral 3 Open Models Deliver Efficiency, Accuracy at Any Scale","source":"NVIDIA Developer Blog","published":"2025-12-02","fetched_at":"2025-12-22T16:47:34.869961943+00:00"}
{"url":"https://developer.nvidia.com/blog/aws-integrates-ai-infrastructure-with-nvidia-nvlink-fusion-for-trainium4-deployment/","title":"AWS Integrates AI Infrastructure with NVIDIA NVLink Fusion for Trainium4 Deployment","source":"NVIDIA Developer Blog","published":"2025-12-02","fetched_at":"2025-12-22T16:47:34.869966924+00:00"}
{"url":"https://developer.nvidia.com/blog/train-small-orchestration-agents-to-solve-big-problems/","title":"Train Small Orchestration Agents to Solve Big Problems","source":"NVIDIA Developer Blog","published":"2025-12-01","fetched_at":"2025-12-22T16:47:34.869971396+00:00"}
{"url":"https://developer.nvidia.com/blog/build-efficient-financial-data-workflows-with-ai-model-distillation/","title":"Build Efficient Financial Data Workflows with AI Model Distillation","source":"NVIDIA Developer Blog","published":"2025-12-01","fetched_at":"2025-12-22T16:47:34.869975507+00:00"}
{"url":"https://developer.nvidia.com/blog/how-to-scale-data-generation-for-physical-ai-with-the-nvidia-cosmos-cookbook/","title":"How to Scale Data Generation for Physical AI with the NVIDIA Cosmos Cookbook","source":"NVIDIA Developer Blog","published":"2025-12-01","fetched_at":"2025-12-22T16:47:34.869979896+00:00"}
{"url":"https://developer.nvidia.com/blog/making-gpu-clusters-more-efficient-with-nvidia-data-center-monitoring/","title":"Making GPU Clusters More Efficient with NVIDIA Data Center Monitoring Tools","source":"NVIDIA Developer Blog","published":"2025-11-25","fetched_at":"2025-12-22T16:47:34.869984091+00:00"}
{"url":"https://developer.nvidia.com/blog/making-robot-perception-more-efficient-on-nvidia-jetson-thor/","title":"Making Robot Perception More Efficient on NVIDIA Jetson Thor","source":"NVIDIA Developer Blog","published":"2025-11-25","fetched_at":"2025-12-22T16:47:34.869988406+00:00"}
{"url":"https://developer.nvidia.com/blog/build-and-run-secure-data-driven-ai-agents/","title":"Build and Run Secure, Data-Driven AI Agents","source":"NVIDIA Developer Blog","published":"2025-11-24","fetched_at":"2025-12-22T16:47:34.869992063+00:00"}
{"url":"https://developer.nvidia.com/blog/model-quantization-concepts-methods-and-why-it-matters/","title":"Model Quantization: Concepts, Methods, and Why It Matters","source":"NVIDIA Developer Blog","published":"2025-11-24","fetched_at":"2025-12-22T16:47:34.869995952+00:00"}
{"url":"https://developer.nvidia.com/blog/breaking-through-rl-training-limits-with-scaling-rollouts-in-brorl/","title":"Breaking Through Reinforcement Learning Training Limits with Scaling Rollouts in BroRL","source":"NVIDIA Developer Blog","published":"2025-11-19","fetched_at":"2025-12-22T16:47:34.870000248+00:00"}
{"url":"https://developer.nvidia.com/blog/building-better-qubits-with-gpu-accelerated-computing/","title":"Building Better Qubits with GPU-Accelerated Computing","source":"NVIDIA Developer Blog","published":"2025-11-19","fetched_at":"2025-12-22T16:47:34.870004063+00:00"}
{"url":"https://developer.nvidia.com/blog/building-scalable-ai-on-enterprise-data-with-nvidia-nemotron-rag-and-microsoft-sql-server-2025/","title":"Building Scalable AI on Enterprise Data with NVIDIA Nemotron RAG and Microsoft SQL Server 2025","source":"NVIDIA Developer Blog","published":"2025-11-18","fetched_at":"2025-12-22T16:47:34.870008387+00:00"}
{"url":"https://developer.nvidia.com/blog/faster-chemistry-and-materials-discovery-with-ai-powered-simulations-using-nvidia-alchemi/","title":"Faster Chemistry and Materials Discovery with AI-Powered Simulations Using NVIDIA ALCHEMI","source":"NVIDIA Developer Blog","published":"2025-11-18","fetched_at":"2025-12-22T16:47:34.870013285+00:00"}
{"url":"https://developer.nvidia.com/blog/nvidia-nvqlink-architecture-integrates-accelerated-computing-with-quantum-processors/","title":"NVIDIA NVQLink Architecture Integrates Accelerated Computing with Quantum Processors","source":"NVIDIA Developer Blog","published":"2025-11-17","fetched_at":"2025-12-22T16:47:34.870018896+00:00"}
{"url":"https://developer.nvidia.com/blog/pioneering-ai-co-scientists-for-fusion-research-and-cancer-treatment/","title":"Pioneering AI Co-Scientists for Fusion Research and Cancer Treatment","source":"NVIDIA Developer Blog","published":"2025-11-17","fetched_at":"2025-12-22T16:47:34.870023424+00:00"}
{"url":"https://developer.nvidia.com/blog/achieve-cutlass-c-performance-with-python-apis-using-cute-dsl/","title":"Achieve CUTLASS C++ Performance with Python APIs Using CuTe DSL","source":"NVIDIA Developer Blog","published":"2025-11-13","fetched_at":"2025-12-22T16:47:34.870027517+00:00"}
{"url":"https://developer.nvidia.com/blog/how-to-get-started-with-neural-shading-for-your-game-or-application/","title":"How to Get Started with Neural Shading for Your Game or Application","source":"NVIDIA Developer Blog","published":"2025-11-13","fetched_at":"2025-12-22T16:47:34.870032109+00:00"}
{"url":"https://developer.nvidia.com/blog/nvidia-blackwell-architecture-sweeps-mlperf-training-v5-1-benchmarks/","title":"NVIDIA Blackwell Architecture Sweeps MLPerf Training v5.1 Benchmarks","source":"NVIDIA Developer Blog","published":"2025-11-13","fetched_at":"2025-12-22T16:47:34.870036332+00:00"}
{"url":"https://github.com/NVIDIA/warp/releases/tag/v1.10.0#new_tab","title":"Just Released: Warp 1.10 Expands JAX Interoperability and Performance","source":"NVIDIA Developer Blog","published":"2025-11-13","fetched_at":"2025-12-22T16:47:34.870040007+00:00"}
{"url":"https://developer.nvidia.com/blog/fusing-communication-and-compute-with-new-device-api-and-copy-engine-collectives-in-nvidia-nccl-2-28/","title":"Fusing Communication and Compute with New Device API and Copy Engine Collectives in NVIDIA NCCL 2.28","source":"NVIDIA Developer Blog","published":"2025-11-11","fetched_at":"2025-12-22T16:47:34.870044544+00:00"}
{"url":"https://www.addevent.com/event/kffjqsqb67nq#new_tab","title":"Upcoming Livestream: Build Visual AI Agents with NVIDIA Cosmos Reason and Metropolis","source":"NVIDIA Developer Blog","published":"2025-11-10","fetched_at":"2025-12-22T16:47:34.870048424+00:00"}
{"url":"https://developer.nvidia.com/blog/building-scalable-and-fault-tolerant-nccl-applications/","title":"Building Scalable and Fault-Tolerant NCCL Applications","source":"NVIDIA Developer Blog","published":"2025-11-10","fetched_at":"2025-12-22T16:47:34.870052517+00:00"}
{"url":"https://developer.nvidia.com/blog/training-xgboost-models-with-gpu-accelerated-polars-dataframes/","title":"Training XGBoost Models with GPU-Accelerated Polars DataFrames","source":"NVIDIA Developer Blog","published":"2025-11-10","fetched_at":"2025-12-22T16:47:34.870056637+00:00"}
{"url":"https://developer.nvidia.com/blog/gen-ai-super-resolution-accelerates-weather-prediction-with-scalable-low-compute-models/","title":"Gen AI Super-Resolution Accelerates Weather Prediction with Scalable, Low-Compute Models","source":"NVIDIA Developer Blog","published":"2025-11-10","fetched_at":"2025-12-22T16:47:34.870060822+00:00"}
{"url":"https://developer.nvidia.com/blog/how-to-achieve-4x-faster-inference-for-math-problem-solving/","title":"How to Achieve 4x Faster Inference for Math Problem Solving","source":"NVIDIA Developer Blog","published":"2025-11-10","fetched_at":"2025-12-22T16:47:34.870064822+00:00"}
{"url":"https://developer.nvidia.com/blog/enabling-multi-node-nvlink-on-kubernetes-for-gb200-and-beyond/","title":"Enabling Multi-Node NVLink on Kubernetes for NVIDIA GB200 NVL72 and Beyond","source":"NVIDIA Developer Blog","published":"2025-11-10","fetched_at":"2025-12-22T16:47:34.870068850+00:00"}
{"url":"https://developer.nvidia.com/blog/streamline-complex-ai-inference-on-kubernetes-with-nvidia-grove/","title":"Streamline Complex AI Inference on Kubernetes with NVIDIA Grove","source":"NVIDIA Developer Blog","published":"2025-11-10","fetched_at":"2025-12-22T16:47:34.870072869+00:00"}
{"url":"https://developer.nvidia.com/blog/building-an-interactive-ai-agent-for-lightning-fast-machine-learning-tasks/","title":"Building an Interactive AI Agent for Lightning-Fast Machine Learning Tasks","source":"NVIDIA Developer Blog","published":"2025-11-07","fetched_at":"2025-12-22T16:47:34.870077378+00:00"}
{"url":"https://developer.nvidia.com/blog/benchmarking-llms-on-ai-generated-cuda-code-with-computeeval-2025-2/","title":"Benchmarking LLMs on AI-Generated CUDA Code with ComputeEval 2025.2","source":"NVIDIA Developer Blog","published":"2025-11-07","fetched_at":"2025-12-22T16:47:34.870081545+00:00"}
{"url":"https://developer.nvidia.com/blog/enhancing-gpu-accelerated-vector-search-in-faiss-with-nvidia-cuvs/","title":"Enhancing GPU-Accelerated Vector Search in Faiss with NVIDIA cuVS","source":"NVIDIA Developer Blog","published":"2025-11-06","fetched_at":"2025-12-22T16:47:34.870085508+00:00"}
{"url":"https://developer.nvidia.com/blog/accelerating-large-scale-mixture-of-experts-training-in-pytorch/","title":"Accelerating Large-Scale Mixture-of-Experts Training in PyTorch","source":"NVIDIA Developer Blog","published":"2025-11-06","fetched_at":"2025-12-22T16:47:34.870089563+00:00"}
{"url":"https://developer.nvidia.com/blog/scale-biology-transformer-models-with-pytorch-and-nvidia-bionemo-recipes/","title":"Scale Biology Transformer Models with PyTorch and NVIDIA BioNeMo Recipes","source":"NVIDIA Developer Blog","published":"2025-11-05","fetched_at":"2025-12-22T16:47:34.870093915+00:00"}
{"url":"https://developer.nvidia.com/blog/how-to-predict-biomolecular-structures-using-the-openfold3-nim/","title":"How to Predict Biomolecular Structures Using the OpenFold3 NIM","source":"NVIDIA Developer Blog","published":"2025-11-04","fetched_at":"2025-12-22T16:47:34.870098174+00:00"}
{"url":"https://developer.nvidia.com/blog/r2d2-perception-guided-task-amp-motion-planning-for-long-horizon-manipulation/","title":"R²D²: Perception-Guided Task & Motion Planning for Long-Horizon Manipulation","source":"NVIDIA Developer Blog","published":"2025-11-04","fetched_at":"2025-12-22T16:47:34.870103933+00:00"}
{"url":"https://developer.nvidia.com/blog/make-sense-of-video-analytics-by-integrating-nvidia-ai-blueprints/","title":"Make Sense of Video Analytics by Integrating NVIDIA AI Blueprints","source":"NVIDIA Developer Blog","published":"2025-11-03","fetched_at":"2025-12-22T16:47:34.870108035+00:00"}
{"url":"https://luma.com/9n27uem4","title":"Join Us for the Blackwell NVFP4 Kernel Hackathon with NVIDIA and GPU MODE","source":"NVIDIA Developer Blog","published":"2025-11-03","fetched_at":"2025-12-22T16:47:34.870111174+00:00"}
{"url":"https://developer.nvidia.com/blog/advancing-explainable-ai-in-radiology-research-with-nvidia-clara-reason/","title":"Advancing Explainable AI in Radiology Research with NVIDIA Clara Reason","source":"NVIDIA Developer Blog","published":"2025-11-03","fetched_at":"2025-12-22T16:47:34.870116128+00:00"}
{"url":"https://developer.nvidia.com/blog/how-code-execution-drives-key-risks-in-agentic-ai-systems/","title":"How Code Execution Drives Key Risks in Agentic AI Systems","source":"NVIDIA Developer Blog","published":"2025-11-03","fetched_at":"2025-12-22T16:47:34.870120017+00:00"}
{"url":"https://developer.nvidia.com/blog/streamline-ai-infrastructure-with-nvidia-runai-on-microsoft-azure/","title":"Streamline AI Infrastructure with NVIDIA Run:ai on Microsoft Azure","source":"NVIDIA Developer Blog","published":"2025-10-30","fetched_at":"2025-12-22T16:47:34.870124693+00:00"}
{"url":"https://developer.nvidia.com/blog/introducing-the-codonfm-open-model-for-rna-design-and-analysis/","title":"Introducing the CodonFM Open Model for RNA Design and Analysis","source":"NVIDIA Developer Blog","published":"2025-10-28","fetched_at":"2025-12-22T16:47:34.870128489+00:00"}
{"url":"https://developer.nvidia.com/blog/accelerating-av-simulation-with-neural-reconstruction-and-world-foundation-models/","title":"Accelerating AV Simulation with Neural Reconstruction and World Foundation Models","source":"NVIDIA Developer Blog","published":"2025-10-28","fetched_at":"2025-12-22T16:47:34.870132887+00:00"}
{"url":"https://developer.nvidia.com/blog/powering-ai-native-6g-research-with-the-nvidia-sionna-research-kit/","title":"Powering AI-Native 6G Research with the NVIDIA Sionna Research Kit","source":"NVIDIA Developer Blog","published":"2025-10-28","fetched_at":"2025-12-22T16:47:34.870137211+00:00"}
{"url":"https://developer.nvidia.com/blog/develop-specialized-ai-agents-with-new-nvidia-nemotron-vision-rag-and-guardrail-models/","title":"Develop Specialized AI Agents with New NVIDIA Nemotron Vision, RAG, and Guardrail Models","source":"NVIDIA Developer Blog","published":"2025-10-28","fetched_at":"2025-12-22T16:47:34.870141498+00:00"}
{"url":"https://developer.nvidia.com/blog/build-synthetic-data-pipelines-to-train-smarter-robots-with-nvidia-isaac-sim/","title":"Build Synthetic Data Pipelines to Train Smarter Robots with NVIDIA Isaac Sim","source":"NVIDIA Developer Blog","published":"2025-10-24","fetched_at":"2025-12-22T16:47:34.870145656+00:00"}
{"url":"https://developer.nvidia.com/blog/unlocking-tensor-core-performance-with-floating-point-emulation-in-cublas/","title":"Unlocking Tensor Core Performance with Floating Point Emulation in cuBLAS","source":"NVIDIA Developer Blog","published":"2025-10-24","fetched_at":"2025-12-22T16:47:34.870149795+00:00"}
{"url":"https://developer.nvidia.com/blog/solve-linear-programs-using-the-gpu-accelerated-barrier-method-in-nvidia-cuopt/","title":"Solve Linear Programs Using the GPU-Accelerated Barrier Method in NVIDIA cuOpt","source":"NVIDIA Developer Blog","published":"2025-10-24","fetched_at":"2025-12-22T16:47:34.870153952+00:00"}
{"url":"https://developer.nvidia.com/blog/how-nvidia-dgx-sparks-performance-enables-intensive-ai-tasks/","title":"How NVIDIA DGX Spark’s Performance Enables Intensive AI Tasks","source":"NVIDIA Developer Blog","published":"2025-10-24","fetched_at":"2025-12-22T16:47:34.870158071+00:00"}
{"url":"https://developer.nvidia.com/blog/reconstruct-a-scene-in-nvidia-isaac-sim-using-only-a-smartphone/","title":"Reconstruct a Scene in NVIDIA Isaac Sim Using Only a Smartphone","source":"NVIDIA Developer Blog","published":"2025-10-23","fetched_at":"2025-12-22T16:47:34.870162655+00:00"}
{"url":"https://developer.nvidia.com/blog/train-an-llm-on-an-nvidia-blackwell-desktop-with-unsloth-and-scale-it/","title":"Train an LLM on NVIDIA Blackwell with Unsloth—and Scale for Production","source":"NVIDIA Developer Blog","published":"2025-10-23","fetched_at":"2025-12-22T16:47:34.870166747+00:00"}
{"url":"https://github.com/gzquse/qgear-lightning","title":"Bring Your Circuits to CUDA-Q Using QGEAR","source":"NVIDIA Developer Blog","published":"2025-10-23","fetched_at":"2025-12-22T16:47:34.870170775+00:00"}
{"url":"https://developer.nvidia.com/blog/create-your-own-bash-computer-use-agent-with-nvidia-nemotron-in-one-hour/","title":"Create Your Own Bash Computer Use Agent with NVIDIA Nemotron in One Hour","source":"NVIDIA Developer Blog","published":"2025-10-22","fetched_at":"2025-12-22T16:47:34.870174979+00:00"}
{"url":"https://www.nvidia.com/en-us/learn/learning-path/deep-learning/","title":"Build Practical Deep-Learning Skills for Real-World AI Applications with the New NVIDIA Learning Path","source":"NVIDIA Developer Blog","published":"2025-10-21","fetched_at":"2025-12-22T16:47:34.870178719+00:00"}
{"url":"https://developer.nvidia.com/blog/nvidia-ace-adds-open-source-qwen3-slm-for-on-device-deployment-in-pc-games/","title":"NVIDIA ACE Adds Open Source Qwen3 SLM for On-Device Deployment in PC Games","source":"NVIDIA Developer Blog","published":"2025-10-21","fetched_at":"2025-12-22T16:47:34.870183164+00:00"}
{"url":"https://developer.nvidia.com/blog/build-an-ai-agent-to-analyze-it-tickets-with-nvidia-nemotron/","title":"Build an AI Agent to Analyze IT Tickets with NVIDIA Nemotron","source":"NVIDIA Developer Blog","published":"2025-10-20","fetched_at":"2025-12-22T16:47:34.870187377+00:00"}
{"url":"https://developer.nvidia.com/blog/enabling-scalable-ai-driven-molecular-dynamics-simulations/","title":"Enabling Scalable AI-Driven Molecular Dynamics Simulations","source":"NVIDIA Developer Blog","published":"2025-10-20","fetched_at":"2025-12-22T16:47:34.870192266+00:00"}
{"url":"https://developer.nvidia.com/blog/scaling-large-moe-models-with-wide-expert-parallelism-on-nvl72-rack-scale-systems/","title":"Scaling Large MoE Models with Wide Expert Parallelism on NVL72 Rack Scale Systems","source":"NVIDIA Developer Blog","published":"2025-10-20","fetched_at":"2025-12-22T16:47:34.870196581+00:00"}
{"url":"https://nvidia-aws.devpost.com/?utm_source=devpost&utm_medium=linkedin&utm_campaign=agenticaiunleashed25","title":"Agentic AI Unleashed: Join the AWS & NVIDIA Hackathon","source":"NVIDIA Developer Blog","published":"2025-10-15","fetched_at":"2025-12-22T16:47:34.870200895+00:00"}
{"url":"https://developer.nvidia.com/blog/unlock-faster-smarter-edge-models-with-7x-gen-ai-performance-on-nvidia-jetson-agx-thor/","title":"Unlock Faster, Smarter Edge Models with 7x Gen AI Performance on NVIDIA Jetson AGX Thor","source":"NVIDIA Developer Blog","published":"2025-10-15","fetched_at":"2025-12-22T16:47:34.870205210+00:00"}
{"url":"https://developer.nvidia.com/blog/accelerated-and-distributed-upf-for-the-era-of-agentic-ai-and-6g/","title":"Accelerated and Distributed UPF for the Era of Agentic AI and 6G","source":"NVIDIA Developer Blog","published":"2025-10-15","fetched_at":"2025-12-22T16:47:34.870209229+00:00"}
{"url":"https://developer.nvidia.com/blog/accelerate-qubit-research-with-nvidia-cuquantum-integrations-in-qutip-and-scqubits/","title":"Accelerate Qubit Research with NVIDIA cuQuantum Integrations in QuTiP and scQubits","source":"NVIDIA Developer Blog","published":"2025-10-14","fetched_at":"2025-12-22T16:47:34.870213358+00:00"}
{"url":"https://developer.nvidia.com/blog/understanding-memory-management-on-hardware-coherent-platforms/","title":"Understanding Memory Management on Hardware-Coherent Platforms","source":"NVIDIA Developer Blog","published":"2025-10-14","fetched_at":"2025-12-22T16:47:34.870217479+00:00"}
{"url":"https://developer.nvidia.com/blog/improve-variant-calling-accuracy-with-nvidia-parabricks/","title":"Improve Variant Calling Accuracy with NVIDIA Parabricks","source":"NVIDIA Developer Blog","published":"2025-10-14","fetched_at":"2025-12-22T16:47:34.870221534+00:00"}
